{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9674339401543441\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load datasets\n",
    "movies_df = pd.read_excel('data/movies_df.xlsx')\n",
    "movies_csv = pd.read_csv('data/movies.csv')\n",
    "train_ratings = pd.read_csv('data/train_ratings.csv')\n",
    "valid_data = pd.read_csv('data/valid_data.csv')\n",
    "\n",
    "# Align movies_df with movies_csv based on movieId\n",
    "aligned_movies_df = movies_csv[['movieId']].merge(movies_df, on='movieId', how='left')\n",
    "\n",
    "# One-hot encode genres\n",
    "genres_matrix = movies_csv['genres'].str.get_dummies(sep='|')\n",
    "\n",
    "# Normalize numerical features from aligned_movies_df (excluding 'overview' column)\n",
    "scaler = MinMaxScaler()\n",
    "numeric_columns = aligned_movies_df.select_dtypes(include=[np.number]).columns\n",
    "numerical_features = scaler.fit_transform(aligned_movies_df[numeric_columns])\n",
    "\n",
    "# Combine features\n",
    "movie_features = np.hstack([genres_matrix.values, numerical_features])\n",
    "\n",
    "# Map movieId to the index in movie_features\n",
    "movie_id_to_index = {movie_id: idx for idx, movie_id in enumerate(movies_csv['movieId'])}\n",
    "\n",
    "# Function to create a feature array for a given user-item pair\n",
    "def get_features(row):\n",
    "    movie_idx = movie_id_to_index.get(row['movieId'])\n",
    "    if movie_idx is not None:\n",
    "        movie_ftrs = movie_features[movie_idx]\n",
    "        return np.hstack([row['rating'], movie_ftrs])\n",
    "    return np.array([np.nan] * (1 + movie_features.shape[1]))\n",
    "\n",
    "# Prepare training data\n",
    "train_data = np.array([get_features(row) for _, row in train_ratings.iterrows()])\n",
    "X_train = train_data[:, 1:]  # Exclude the rating column\n",
    "y_train = train_data[:, 0]   # Only the rating column\n",
    "\n",
    "# Prepare validation data\n",
    "valid_data_features = np.array([get_features(row) for _, row in valid_data.iterrows()])\n",
    "X_valid = valid_data_features[:, 1:]  # Exclude the rating column\n",
    "y_valid = valid_data_features[:, 0]   # Only the rating column\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute missing values in the training data\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Impute missing values in the validation data\n",
    "X_valid_imputed = imputer.transform(X_valid)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_valid_imputed)\n",
    "\n",
    "# Calculating RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def create_user_item_matrix(df):\n",
    "    \"\"\" Create a user-item matrix for collaborative filtering \"\"\"\n",
    "    user_ids = df['userId'].unique()\n",
    "    movie_ids = df['movieId'].unique()\n",
    "    \n",
    "    user_id_to_idx = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "    movie_id_to_idx = {movie_id: idx for idx, movie_id in enumerate(movie_ids)}\n",
    "    \n",
    "    rows = df['userId'].map(user_id_to_idx)\n",
    "    cols = df['movieId'].map(movie_id_to_idx)\n",
    "    values = df['rating']\n",
    "    \n",
    "    return csr_matrix((values, (rows, cols)), shape=(len(user_ids), len(movie_ids))), user_id_to_idx, movie_id_to_idx\n",
    "\n",
    "# Create user-item matrices for train and validation data\n",
    "train_matrix, train_user_id_to_idx, train_movie_id_to_idx = create_user_item_matrix(train_ratings)\n",
    "valid_matrix, valid_user_id_to_idx, valid_movie_id_to_idx = create_user_item_matrix(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9296953834375242"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def calculate_biases(ratings_df):\n",
    "    global_mean = ratings_df['rating'].mean()\n",
    "\n",
    "    user_bias = ratings_df.groupby('userId')['rating'].mean() - global_mean\n",
    "    item_bias = ratings_df.groupby('movieId')['rating'].mean() - global_mean\n",
    "\n",
    "    return global_mean, user_bias, item_bias\n",
    "\n",
    "def predict_with_biases(U, sigma, Vt, user_id_to_idx, movie_id_to_idx, global_mean, user_bias, item_bias, userId, movieId):\n",
    "    user_idx = user_id_to_idx.get(userId)\n",
    "    movie_idx = movie_id_to_idx.get(movieId)\n",
    "\n",
    "    if user_idx is not None and movie_idx is not None:\n",
    "        pred_rating = np.dot(np.dot(U[user_idx, :], sigma), Vt[:, movie_idx])\n",
    "        pred_rating += global_mean\n",
    "        pred_rating += user_bias.get(userId, 0)\n",
    "        pred_rating += item_bias.get(movieId, 0)\n",
    "        return pred_rating\n",
    "    else:\n",
    "        return global_mean\n",
    "\n",
    "# Calculate biases\n",
    "global_mean, user_bias, item_bias = calculate_biases(train_ratings)\n",
    "\n",
    "# Perform SVD\n",
    "U, sigma, Vt = svds(train_matrix, k=500)\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "# Make predictions and calculate RMSE\n",
    "predicted_ratings = []\n",
    "for _, row in valid_data.iterrows():\n",
    "    predicted_rating = predict_with_biases(U, sigma, Vt, train_user_id_to_idx, train_movie_id_to_idx, \n",
    "                                           global_mean, user_bias, item_bias, row.userId, row.movieId)\n",
    "    predicted_ratings.append(predicted_rating)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(valid_data['rating'], predicted_ratings))\n",
    "rmse\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
