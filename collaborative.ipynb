{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T10:32:58.611001592Z",
     "start_time": "2023-11-18T10:32:58.555181184Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6baf1458186460b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T10:32:58.866848584Z",
     "start_time": "2023-11-18T10:32:58.851176313Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d802ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "movies_df = pd.read_excel(f'{DATA_DIR}movies_df.xlsx')\n",
    "movies_csv = pd.read_csv(f'{DATA_DIR}movies.csv')\n",
    "train_ratings = pd.read_csv(f'{DATA_DIR}train_ratings.csv')\n",
    "# split train data into train and validation data\n",
    "valid_data = train_ratings.iloc[int(len(train_ratings)*0.8):]\n",
    "train_ratings = train_ratings.iloc[:int(len(train_ratings)*0.8)]\n",
    "\n",
    "def create_user_item_matrix(df):\n",
    "    \"\"\" Create a user-item matrix for collaborative filtering \"\"\"\n",
    "    user_ids = df['userId'].unique()\n",
    "    movie_ids = df['movieId'].unique()\n",
    "    \n",
    "    user_id_to_idx = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "    movie_id_to_idx = {movie_id: idx for idx, movie_id in enumerate(movie_ids)}\n",
    "    \n",
    "    rows = df['userId'].map(user_id_to_idx)\n",
    "    cols = df['movieId'].map(movie_id_to_idx)\n",
    "    values = df['rating']\n",
    "    \n",
    "    return csr_matrix((values, (rows, cols)), shape=(len(user_ids), len(movie_ids))), user_id_to_idx, movie_id_to_idx\n",
    "\n",
    "# Create user-item matrices for train and validation data\n",
    "train_matrix, train_user_id_to_idx, train_movie_id_to_idx = create_user_item_matrix(train_ratings)\n",
    "valid_matrix, valid_user_id_to_idx, valid_movie_id_to_idx = create_user_item_matrix(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcfa39d1630da196",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T10:34:01.474744322Z",
     "start_time": "2023-11-18T10:34:01.463381003Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate item and user similarities\n",
    "item_sim = train_matrix.T.dot(train_matrix).toarray()\n",
    "user_sim = train_matrix.dot(train_matrix.T).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "094dabb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_biases(ratings_df):\n",
    "    global_mean = ratings_df['rating'].mean()\n",
    "\n",
    "    user_bias = ratings_df.groupby('userId')['rating'].mean() - global_mean\n",
    "    item_bias = ratings_df.groupby('movieId')['rating'].mean() - global_mean\n",
    "\n",
    "    return global_mean, user_bias, item_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "515d28af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate biases\n",
    "global_mean, user_bias, item_bias = calculate_biases(train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e810329a05bacb9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T10:34:06.319247931Z",
     "start_time": "2023-11-18T10:34:06.308026189Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item-based CF MSE: 1.7926032366667275\n"
     ]
    }
   ],
   "source": [
    "# Predict using item similarities\n",
    "def predict_item_based(user_id, movie_id, k=500, item_bias=item_bias, global_mean=global_mean, user_bias=user_bias):\n",
    "    \"\"\" Predict rating for a given user and movie using item-based collaborative filtering \"\"\"\n",
    "    if user_id not in train_user_id_to_idx:\n",
    "        return global_mean\n",
    "    if movie_id not in train_movie_id_to_idx:\n",
    "        return global_mean\n",
    "    # Get index of user and movie\n",
    "    user_idx = train_user_id_to_idx[user_id]\n",
    "    movie_idx = train_movie_id_to_idx[movie_id]\n",
    "    \n",
    "    # Get k most similar items to movie\n",
    "    similar_items = np.argsort(item_sim[movie_idx])[-k:]\n",
    "    \n",
    "    # Get ratings for similar items\n",
    "    similar_ratings = train_matrix[user_idx, similar_items].toarray().ravel()\n",
    "    \n",
    "    # Get similarities for similar items\n",
    "    similarities = item_sim[movie_idx, similar_items]\n",
    "    \n",
    "    # Predict rating as weighted average of ratings of similar items\n",
    "    prediction = np.sum(similar_ratings * similarities) / np.sum(similarities)\n",
    "    \n",
    "    # Add item bias to prediction\n",
    "    prediction += item_bias[movie_id]\n",
    "    \n",
    "    # Add global mean and user bias to prediction\n",
    "    prediction += global_mean + user_bias[user_id]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "predictions = []\n",
    "actuals = []\n",
    "for _, row in valid_data.iterrows():\n",
    "    #print(row['userId'], row['movieId'])\n",
    "    predictions.append(predict_item_based(row['userId'], row['movieId']))\n",
    "    actuals.append(row['rating'])\n",
    "\n",
    "print('Item-based CF MSE:', mean_squared_error(actuals, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a947e224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF MSE: 1.390212936000763\n"
     ]
    }
   ],
   "source": [
    "# Predict using user similarities\n",
    "def predict_user_based(user_id, movie_id, k=500, user_bias=user_bias, global_mean=global_mean, item_bias=item_bias):\n",
    "    \"\"\" Predict rating for a given user and movie using user-based collaborative filtering \"\"\"\n",
    "    if user_id not in train_user_id_to_idx:\n",
    "        return global_mean\n",
    "    if movie_id not in train_movie_id_to_idx:\n",
    "        return global_mean\n",
    "    # Get index of user and movie\n",
    "    user_idx = train_user_id_to_idx[user_id]\n",
    "    movie_idx = train_movie_id_to_idx[movie_id]\n",
    "    \n",
    "    # Get k most similar users to user\n",
    "    similar_users = np.argsort(user_sim[user_idx])[-k:]\n",
    "    \n",
    "    # Get ratings for similar users\n",
    "    similar_ratings = train_matrix[similar_users, movie_idx].toarray().ravel()\n",
    "    \n",
    "    # Get similarities for similar users\n",
    "    similarities = user_sim[user_idx, similar_users]\n",
    "    \n",
    "    # Predict rating as weighted average of ratings of similar users\n",
    "    prediction = np.sum(similar_ratings * similarities) / np.sum(similarities)\n",
    "    \n",
    "    # Add user bias to prediction\n",
    "    prediction += user_bias[user_id]\n",
    "    \n",
    "    # Add global mean and item bias to prediction\n",
    "    prediction += global_mean + item_bias[movie_id]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "predictions = []\n",
    "actuals = []\n",
    "for _, row in valid_data.iterrows():\n",
    "    predictions.append(predict_user_based(row['userId'], row['movieId']))\n",
    "    actuals.append(row['rating'])\n",
    "\n",
    "print('User-based CF MSE:', mean_squared_error(actuals, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd5ca24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
