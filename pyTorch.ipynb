{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import GloVe\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch_utils import MovieRatingDataset, Recommender, device\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "tag_vocab = MovieRatingDataset.build_tag_vocab(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MovieRatingDataset(\n",
    "    tag_vocab=tag_vocab,\n",
    "    tokenizer=tokenizer,\n",
    "    train='train'\n",
    ")\n",
    "\n",
    "valid_data = MovieRatingDataset(\n",
    "    tag_vocab=tag_vocab,\n",
    "    tokenizer=tokenizer,\n",
    "    train='valid'\n",
    ")\n",
    "\n",
    "test_data = MovieRatingDataset(\n",
    "    tag_vocab=tag_vocab,\n",
    "    tokenizer=tokenizer,\n",
    "    train='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_embeds = 50\n",
    "vec = GloVe(name='6B', dim=tag_embeds)\n",
    "embeddings = vec.get_vecs_by_tokens(train_data.vocab.get_itos(), lower_case_backup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag_string in train_data.vocab.get_itos():\n",
    "    vec_embed = vec[tag_string]\n",
    "    embed_embed = embeddings[train_data.vocab[tag_string]]\n",
    "    assert np.allclose(vec_embed, embed_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Recommender(\n",
    "    num_users=len(train_data.data_df['user_label'].unique()),\n",
    "    num_movies=train_data.movies.shape[0],\n",
    "    num_genres=len(train_data.genres_df.columns),\n",
    "    num_tags=len(train_data.vocab),\n",
    "    user_movie_embed=10,\n",
    "    tag_embed=tag_embeds,\n",
    "    tag_weights=embeddings,\n",
    "    device=device,\n",
    "    freeze=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_embedding.weight\n",
      "movie_embedding.weight\n",
      "fc.0.weight\n",
      "fc.0.bias\n",
      "fc.3.weight\n",
      "fc.3.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our Loss\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# Define our optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "# Define our data loaders\n",
    "train_data_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=len(train_data),\n",
    "    shuffle=True,\n",
    "    collate_fn=model.collate_fn\n",
    ")\n",
    "\n",
    "valid_data_loader = DataLoader(\n",
    "    valid_data,\n",
    "    batch_size=len(valid_data),\n",
    "    shuffle=False,\n",
    "    collate_fn=model.collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=len(test_data),\n",
    "    shuffle=False,\n",
    "    collate_fn=model.collate_fn_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_extracted = None\n",
    "for batch in train_data_loader:\n",
    "    train_data_extracted = batch\n",
    "\n",
    "valid_data_extracted = None\n",
    "for batch in valid_data_loader:\n",
    "    valid_data_extracted = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_ratings, all_train_data = train_data_extracted\n",
    "all_valid_ratings, all_valid_data = valid_data_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, movies, genres, tags, lang, budget, popularity, runtime, vote_average, vote_count, revenue, overview_embeddings = all_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.8602, -0.2087,  4.7406,  ..., 12.1812,  0.9682,  2.9556],\n",
       "        [10.4047,  0.1298,  3.9398,  ..., 11.4039,  1.8472,  3.3035],\n",
       "        [10.4192,  0.3383,  4.2487,  ..., 12.2143,  2.1025,  2.5916],\n",
       "        ...,\n",
       "        [ 9.5527, -0.4575,  4.7554,  ..., 11.8770,  0.5459,  2.9962],\n",
       "        [ 8.9806, -1.3935,  3.7656,  ..., 12.0576,  1.1271,  2.5512],\n",
       "        [ 9.6700, -0.5782,  4.1318,  ..., 12.1648,  1.5044,  2.7012]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train MSE Loss: 0.669, Valid RMSE Loss: 0.832: 100%|██████████| 2200/2200 [08:35<00:00,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train MSE Loss: 0.669, Valid RMSE Loss: 0.832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "from tqdm import tqdm\n",
    "epochs = 2200\n",
    "pbar = tqdm(range(epochs))\n",
    "last_valid_loss = \"???\"\n",
    "for epoch in pbar:\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(all_train_data)\n",
    "    loss_value = loss(predictions, all_train_ratings)\n",
    "    loss_value.backward()\n",
    "    optimizer.step()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Calculate RMSE\n",
    "        predictions = model(all_valid_data)\n",
    "        valid_loss = mean_squared_error(predictions.cpu(), all_valid_ratings.cpu(), squared=False)\n",
    "        last_valid_loss = valid_loss\n",
    "    pbar.set_description(f\"Train MSE Loss: {loss_value.item():.3f}, Valid RMSE Loss: {last_valid_loss:.3f}\")\n",
    "    pbar.update()\n",
    "\n",
    "print(f\"Final Train MSE Loss: {loss_value.item():.3f}, Valid RMSE Loss: {last_valid_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predictions: 100%|██████████| 1/1 [00:04<00:00,  4.08s/it]\n"
     ]
    }
   ],
   "source": [
    "# Now let's do the predictions on the test set\n",
    "model.eval()\n",
    "predictions = {} # A dict with row_id as key and rating as value\n",
    "# Since the test_data_loader has shuffle=False, \n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_data_loader, leave=True, desc=\"Predictions\"):\n",
    "        row_id, inputs = batch\n",
    "        predictions_batch = model(inputs)\n",
    "        for row_id, prediction in zip(row_id, predictions_batch):\n",
    "            predictions[row_id.item()] = prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.191563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.224806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.997659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.840130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.431867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating\n",
       "Id          \n",
       "0   3.191563\n",
       "1   3.224806\n",
       "2   2.997659\n",
       "3   3.840130\n",
       "4   3.431867"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the predictions dict, we build a dataframe\n",
    "submission_df = pd.DataFrame.from_dict(predictions, orient='index', columns=['rating'])\n",
    "submission_df.index.name = 'Id'\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.025945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.435218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.572485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.854323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.353108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating\n",
       "Id          \n",
       "0   3.025945\n",
       "1   3.435218\n",
       "2   2.572485\n",
       "3   3.854323\n",
       "4   3.353108"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the predictions dict, we build a dataframe\n",
    "submission_df = pd.DataFrame.from_dict(predictions, orient='index', columns=['rating'])\n",
    "submission_df.index.name = 'Id'\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to a csv file\n",
    "submission_df.to_csv('submission_new_approach13.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
