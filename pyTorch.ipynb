{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import GloVe\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch_utils import MovieRatingDataset, Recommender, device\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "tag_vocab = MovieRatingDataset.build_tag_vocab(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MovieRatingDataset(\n",
    "    tag_vocab=tag_vocab,\n",
    "    tokenizer=tokenizer,\n",
    "    train='train'\n",
    ")\n",
    "\n",
    "valid_data = MovieRatingDataset(\n",
    "    tag_vocab=tag_vocab,\n",
    "    tokenizer=tokenizer,\n",
    "    train='valid'\n",
    ")\n",
    "\n",
    "test_data = MovieRatingDataset(\n",
    "    tag_vocab=tag_vocab,\n",
    "    tokenizer=tokenizer,\n",
    "    train='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_embeds = 50\n",
    "vec = GloVe(name='6B', dim=tag_embeds)\n",
    "embeddings = vec.get_vecs_by_tokens(train_data.vocab.get_itos(), lower_case_backup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag_string in train_data.vocab.get_itos():\n",
    "    vec_embed = vec[tag_string]\n",
    "    embed_embed = embeddings[train_data.vocab[tag_string]]\n",
    "    assert np.allclose(vec_embed, embed_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Recommender(\n",
    "    num_users=len(train_data.data_df['user_label'].unique()),\n",
    "    num_movies=train_data.movies.shape[0],\n",
    "    num_genres=len(train_data.genres_df.columns),\n",
    "    num_tags=len(train_data.vocab),\n",
    "    user_movie_embed=10,\n",
    "    tag_embed=tag_embeds,\n",
    "    tag_weights=embeddings,\n",
    "    device=device,\n",
    "    freeze=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_embedding.weight\n",
      "movie_embedding.weight\n",
      "fc.0.weight\n",
      "fc.0.bias\n",
      "fc.3.weight\n",
      "fc.3.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our Loss\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# Define our optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define our data loaders\n",
    "train_data_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=len(train_data),\n",
    "    shuffle=True,\n",
    "    collate_fn=model.collate_fn\n",
    ")\n",
    "\n",
    "valid_data_loader = DataLoader(\n",
    "    valid_data,\n",
    "    batch_size=1024*5,\n",
    "    shuffle=False,\n",
    "    collate_fn=model.collate_fn\n",
    ")\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=1024*5,\n",
    "    shuffle=False,\n",
    "    collate_fn=model.collate_fn_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_extracted = None\n",
    "for batch in train_data_loader:\n",
    "    train_data_extracted = batch\n",
    "\n",
    "valid_data_extracted = None\n",
    "for batch in valid_data_loader:\n",
    "    valid_data_extracted = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_ratings, all_train_data = train_data_extracted\n",
    "all_valid_ratings, all_valid_data = valid_data_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train MSE Loss: 0.893, Valid RMSE Loss: 0.852: 100%|██████████| 800/800 [00:45<00:00, 17.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train MSE Loss: 0.893, Valid RMSE Loss: 0.852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "from tqdm import tqdm\n",
    "epochs = 800\n",
    "pbar = tqdm(range(epochs))\n",
    "last_valid_loss = \"???\"\n",
    "for epoch in pbar:\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(all_train_data)\n",
    "    loss_value = loss(predictions, all_train_ratings)\n",
    "    loss_value.backward()\n",
    "    optimizer.step()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Calculate RMSE\n",
    "        predictions = model(all_valid_data)\n",
    "        valid_loss = mean_squared_error(predictions.cpu(), all_valid_ratings.cpu(), squared=False)\n",
    "        last_valid_loss = valid_loss\n",
    "    pbar.set_description(f\"Train MSE Loss: {loss_value.item():.3f}, Valid RMSE Loss: {last_valid_loss:.3f}\")\n",
    "    pbar.update()\n",
    "\n",
    "print(f\"Final Train MSE Loss: {loss_value.item():.3f}, Valid RMSE Loss: {last_valid_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predictions: 100%|██████████| 4/4 [00:09<00:00,  2.43s/it]\n"
     ]
    }
   ],
   "source": [
    "# Now let's do the predictions on the test set\n",
    "model.eval()\n",
    "predictions = {} # A dict with row_id as key and rating as value\n",
    "# Since the test_data_loader has shuffle=False, \n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_data_loader, leave=True, desc=\"Predictions\"):\n",
    "        row_id, inputs = batch\n",
    "        predictions_batch = model(inputs)\n",
    "        for row_id, prediction in zip(row_id, predictions_batch):\n",
    "            predictions[row_id.item()] = prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.994697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.244906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.666244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.791827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.531365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating\n",
       "Id          \n",
       "0   2.994697\n",
       "1   3.244906\n",
       "2   2.666244\n",
       "3   3.791827\n",
       "4   3.531365"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the predictions dict, we build a dataframe\n",
    "submission_df = pd.DataFrame.from_dict(predictions, orient='index', columns=['rating'])\n",
    "submission_df.index.name = 'Id'\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to a csv file\n",
    "submission_df.to_csv('submission_new_approach3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
