{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import GloVe\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch_utils import MovieRatingDataset, Recommender, device\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "tag_vocab = MovieRatingDataset.build_tag_vocab(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MovieRatingDataset(\n",
    "    tag_vocab=tag_vocab,\n",
    "    tokenizer=tokenizer,\n",
    "    train='train'\n",
    ")\n",
    "\n",
    "valid_data = MovieRatingDataset(\n",
    "    tag_vocab=tag_vocab,\n",
    "    tokenizer=tokenizer,\n",
    "    train='valid'\n",
    ")\n",
    "\n",
    "test_data = MovieRatingDataset(\n",
    "    tag_vocab=tag_vocab,\n",
    "    tokenizer=tokenizer,\n",
    "    train='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_embeds = 50\n",
    "vec = GloVe(name='6B', dim=tag_embeds)\n",
    "embeddings = vec.get_vecs_by_tokens(train_data.vocab.get_itos(), lower_case_backup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag_string in train_data.vocab.get_itos():\n",
    "    vec_embed = vec[tag_string]\n",
    "    embed_embed = embeddings[train_data.vocab[tag_string]]\n",
    "    assert np.allclose(vec_embed, embed_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim: 48\n"
     ]
    }
   ],
   "source": [
    "model = Recommender(\n",
    "    num_users=len(train_data.data_df['user_label'].unique()),\n",
    "    num_movies=train_data.movies.shape[0],\n",
    "    num_genres=len(train_data.genres_df.columns),\n",
    "    num_tags=len(train_data.vocab),\n",
    "    user_movie_embed=10,\n",
    "    tag_embed=tag_embeds,\n",
    "    tag_weights=embeddings,\n",
    "    device=device,\n",
    "    freeze=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_embedding.weight\n",
      "movie_embedding.weight\n",
      "fc.0.weight\n",
      "fc.0.bias\n",
      "fc.3.weight\n",
      "fc.3.bias\n",
      "fc.6.weight\n",
      "fc.6.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our Loss\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# Define our optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "# Define our data loaders\n",
    "train_data_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=len(train_data),\n",
    "    shuffle=True,\n",
    "    collate_fn=model.collate_fn\n",
    ")\n",
    "\n",
    "valid_data_loader = DataLoader(\n",
    "    valid_data,\n",
    "    batch_size=len(valid_data),\n",
    "    shuffle=False,\n",
    "    collate_fn=model.collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=len(test_data),\n",
    "    shuffle=False,\n",
    "    collate_fn=model.collate_fn_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_extracted = None\n",
    "for batch in train_data_loader:\n",
    "    train_data_extracted = batch\n",
    "\n",
    "valid_data_extracted = None\n",
    "for batch in valid_data_loader:\n",
    "    valid_data_extracted = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_ratings, all_train_data = train_data_extracted\n",
    "all_valid_ratings, all_valid_data = valid_data_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, movies, genres, tags, lang, budget, popularity, runtime, vote_average, vote_count, revenue, overview_embeddings = all_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.2400,  0.0671,  4.1502,  ..., 11.4720,  1.3777,  2.4046],\n",
       "        [10.0204,  0.1261,  4.4729,  ..., 11.9630,  1.2093,  3.8267],\n",
       "        [10.4805,  0.2603,  4.1470,  ..., 12.0793,  1.9890,  3.3217],\n",
       "        ...,\n",
       "        [ 9.6916, -2.9879,  3.2266,  ..., 11.8166,  1.4274,  1.1359],\n",
       "        [ 9.1674, -2.9744,  3.0649,  ..., 11.8258,  1.3218,  1.2727],\n",
       "        [10.6505,  0.4716,  4.4205,  ..., 11.8701,  1.7616,  2.4487]],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train MSE Loss: 0.646, Valid RMSE Loss: 0.827: 100%|██████████| 2200/2200 [02:10<00:00, 16.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train MSE Loss: 0.646, Valid RMSE Loss: 0.827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "from tqdm import tqdm\n",
    "epochs = 2200\n",
    "pbar = tqdm(range(epochs))\n",
    "last_valid_loss = \"???\"\n",
    "for epoch in pbar:\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(all_train_data)\n",
    "    loss_value = loss(predictions, all_train_ratings)\n",
    "    loss_value.backward()\n",
    "    optimizer.step()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Calculate RMSE\n",
    "        predictions = model(all_valid_data)\n",
    "        valid_loss = mean_squared_error(predictions.cpu(), all_valid_ratings.cpu(), squared=False)\n",
    "        last_valid_loss = valid_loss\n",
    "    pbar.set_description(f\"Train MSE Loss: {loss_value.item():.3f}, Valid RMSE Loss: {last_valid_loss:.3f}\")\n",
    "    pbar.update()\n",
    "\n",
    "print(f\"Final Train MSE Loss: {loss_value.item():.3f}, Valid RMSE Loss: {last_valid_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predictions: 100%|██████████| 1/1 [00:10<00:00, 10.57s/it]\n"
     ]
    }
   ],
   "source": [
    "# Now let's do the predictions on the test set\n",
    "model.eval()\n",
    "predictions = {} # A dict with row_id as key and rating as value\n",
    "# Since the test_data_loader has shuffle=False, \n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_data_loader, leave=True, desc=\"Predictions\"):\n",
    "        row_id, inputs = batch\n",
    "        predictions_batch = model(inputs)\n",
    "        for row_id, prediction in zip(row_id, predictions_batch):\n",
    "            predictions[row_id.item()] = prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.008922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.263643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.111709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.692470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.401341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating\n",
       "Id          \n",
       "0   3.008922\n",
       "1   3.263643\n",
       "2   3.111709\n",
       "3   3.692470\n",
       "4   3.401341"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the predictions dict, we build a dataframe\n",
    "submission_df = pd.DataFrame.from_dict(predictions, orient='index', columns=['rating'])\n",
    "submission_df.index.name = 'Id'\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.008922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.263643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.111709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.692470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.401341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating\n",
       "Id          \n",
       "0   3.008922\n",
       "1   3.263643\n",
       "2   3.111709\n",
       "3   3.692470\n",
       "4   3.401341"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the predictions dict, we build a dataframe\n",
    "submission_df = pd.DataFrame.from_dict(predictions, orient='index', columns=['rating'])\n",
    "submission_df.index.name = 'Id'\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to a csv file\n",
    "submission_df.to_csv('submission_new_approach14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
