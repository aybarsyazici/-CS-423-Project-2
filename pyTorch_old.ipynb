{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test = pd.read_csv('data/test_set_no_ratings.csv')\n",
    "# 1. Load Data\n",
    "train = pd.read_csv('data/train_ratings.csv')\n",
    "movies = pd.read_csv('data/movies.csv')\n",
    "\n",
    "# 2. Pre-processing: Convert genres into a binary encoded vector\n",
    "movies['genres'] = movies['genres'].str.split('|')\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_encoded = mlb.fit_transform(movies['genres'])\n",
    "genres_df = pd.DataFrame(genres_encoded, columns=mlb.classes_, index=movies.movieId)\n",
    "\n",
    "# Merge genres data with main data\n",
    "train = train.merge(genres_df, left_on='movieId', right_index=True)\n",
    "test = test.merge(genres_df, left_on='movieId', right_index=True)\n",
    "\n",
    "\n",
    "# 3. Encode users and movies as integer indices\n",
    "user_enc = LabelEncoder()\n",
    "train['user'] = user_enc.fit_transform(train['userId'])\n",
    "test['user'] = user_enc.transform(test['userId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_enc = LabelEncoder()\n",
    "all_movies = movies['movieId'].unique().tolist()\n",
    "movie_enc.fit(all_movies)\n",
    "train['movie'] = movie_enc.transform(train['movieId'])\n",
    "test['movie'] = movie_enc.transform(test['movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>...</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>432</td>\n",
       "      <td>77866</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>431</td>\n",
       "      <td>7333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>288</td>\n",
       "      <td>474</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>287</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>285</td>\n",
       "      <td>474</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>539</td>\n",
       "      <td>599</td>\n",
       "      <td>474</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>598</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>1789</td>\n",
       "      <td>447</td>\n",
       "      <td>474</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>446</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20147</th>\n",
       "      <td>20147</td>\n",
       "      <td>509</td>\n",
       "      <td>103042</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>508</td>\n",
       "      <td>8183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20153</th>\n",
       "      <td>20153</td>\n",
       "      <td>212</td>\n",
       "      <td>140715</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>9024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20158</th>\n",
       "      <td>20158</td>\n",
       "      <td>522</td>\n",
       "      <td>27006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>521</td>\n",
       "      <td>5608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160</th>\n",
       "      <td>20160</td>\n",
       "      <td>599</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>598</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20161</th>\n",
       "      <td>20161</td>\n",
       "      <td>596</td>\n",
       "      <td>181719</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>595</td>\n",
       "      <td>9663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20168 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  userId  movieId  (no genres listed)  Action  Adventure  \\\n",
       "0          0     432    77866                   0       1          1   \n",
       "1          1     288      474                   0       1          0   \n",
       "196      196     285      474                   0       1          0   \n",
       "539      539     599      474                   0       1          0   \n",
       "1789    1789     447      474                   0       1          0   \n",
       "...      ...     ...      ...                 ...     ...        ...   \n",
       "20147  20147     509   103042                   0       1          1   \n",
       "20153  20153     212   140715                   0       0          0   \n",
       "20158  20158     522    27006                   0       0          0   \n",
       "20160  20160     599      229                   0       0          0   \n",
       "20161  20161     596   181719                   1       0          0   \n",
       "\n",
       "       Animation  Children  Comedy  Crime  ...  IMAX  Musical  Mystery  \\\n",
       "0              0         0       0      0  ...     0        0        0   \n",
       "1              0         0       0      0  ...     0        0        0   \n",
       "196            0         0       0      0  ...     0        0        0   \n",
       "539            0         0       0      0  ...     0        0        0   \n",
       "1789           0         0       0      0  ...     0        0        0   \n",
       "...          ...       ...     ...    ...  ...   ...      ...      ...   \n",
       "20147          0         0       0      0  ...     1        0        0   \n",
       "20153          0         0       0      0  ...     0        0        0   \n",
       "20158          0         0       0      0  ...     0        0        0   \n",
       "20160          0         0       0      0  ...     0        0        0   \n",
       "20161          0         0       0      0  ...     0        0        0   \n",
       "\n",
       "       Romance  Sci-Fi  Thriller  War  Western  user  movie  \n",
       "0            1       0         0    1        0   431   7333  \n",
       "1            0       0         1    0        0   287    412  \n",
       "196          0       0         1    0        0   284    412  \n",
       "539          0       0         1    0        0   598    412  \n",
       "1789         0       0         1    0        0   446    412  \n",
       "...        ...     ...       ...  ...      ...   ...    ...  \n",
       "20147        0       1         0    0        0   508   8183  \n",
       "20153        0       0         0    0        0   211   9024  \n",
       "20158        0       0         0    0        0   521   5608  \n",
       "20160        0       0         1    0        0   598    195  \n",
       "20161        0       0         0    0        0   595   9663  \n",
       "\n",
       "[20168 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Split the data\n",
    "X = train[['user', 'movie'] + mlb.classes_.tolist()]\n",
    "y = train['rating']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.long).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.long).to(device)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# 5. Build the Model\n",
    "class Recommender(nn.Module):\n",
    "    def __init__(self, num_users, num_movies, num_genres, emb_size):\n",
    "        super(Recommender, self).__init__()\n",
    "        \n",
    "        self.user_embedding = nn.Embedding(num_users, emb_size)\n",
    "        self.movie_embedding = nn.Embedding(num_movies, emb_size)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(emb_size*2 + num_genres, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        user_input = x[:, 0]\n",
    "        movie_input = x[:, 1]\n",
    "        genres_input = x[:, 2:].float()\n",
    "        \n",
    "        user_emb = self.user_embedding(user_input)\n",
    "        movie_emb = self.movie_embedding(movie_input)\n",
    "        \n",
    "        concat = torch.cat([user_emb, movie_emb, genres_input], dim=1)\n",
    "        out = self.fc(concat)\n",
    "        \n",
    "        return out.squeeze()\n",
    "\n",
    "num_users = len(user_enc.classes_)\n",
    "num_movies = len(movie_enc.classes_)\n",
    "\n",
    "# 6. Train the Model\n",
    "model = Recommender(num_users, num_movies, len(mlb.classes_), 15).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/750, Training Loss: 13.077527046203613, Validation Loss: 12.596870422363281\n",
      "Epoch 2/750, Training Loss: 12.717727661132812, Validation Loss: 12.25339412689209\n",
      "Epoch 3/750, Training Loss: 12.36933708190918, Validation Loss: 11.924880027770996\n",
      "Epoch 4/750, Training Loss: 12.03852653503418, Validation Loss: 11.609776496887207\n",
      "Epoch 5/750, Training Loss: 11.718239784240723, Validation Loss: 11.305730819702148\n",
      "Epoch 6/750, Training Loss: 11.406681060791016, Validation Loss: 11.010274887084961\n",
      "Epoch 7/750, Training Loss: 11.09707260131836, Validation Loss: 10.721116065979004\n",
      "Epoch 8/750, Training Loss: 10.79733943939209, Validation Loss: 10.435470581054688\n",
      "Epoch 9/750, Training Loss: 10.502847671508789, Validation Loss: 10.15091609954834\n",
      "Epoch 10/750, Training Loss: 10.206491470336914, Validation Loss: 9.86532211303711\n",
      "Epoch 11/750, Training Loss: 9.91608715057373, Validation Loss: 9.577055931091309\n",
      "Epoch 12/750, Training Loss: 9.61827278137207, Validation Loss: 9.284603118896484\n",
      "Epoch 13/750, Training Loss: 9.327420234680176, Validation Loss: 8.986865043640137\n",
      "Epoch 14/750, Training Loss: 9.01794147491455, Validation Loss: 8.683260917663574\n",
      "Epoch 15/750, Training Loss: 8.712132453918457, Validation Loss: 8.373591423034668\n",
      "Epoch 16/750, Training Loss: 8.40314769744873, Validation Loss: 8.057778358459473\n",
      "Epoch 17/750, Training Loss: 8.086808204650879, Validation Loss: 7.73607873916626\n",
      "Epoch 18/750, Training Loss: 7.768731117248535, Validation Loss: 7.408953666687012\n",
      "Epoch 19/750, Training Loss: 7.435990810394287, Validation Loss: 7.077024936676025\n",
      "Epoch 20/750, Training Loss: 7.107178211212158, Validation Loss: 6.741002082824707\n",
      "Epoch 21/750, Training Loss: 6.775251388549805, Validation Loss: 6.401801109313965\n",
      "Epoch 22/750, Training Loss: 6.436251640319824, Validation Loss: 6.060391902923584\n",
      "Epoch 23/750, Training Loss: 6.1008620262146, Validation Loss: 5.717958927154541\n",
      "Epoch 24/750, Training Loss: 5.765411376953125, Validation Loss: 5.375798225402832\n",
      "Epoch 25/750, Training Loss: 5.424883842468262, Validation Loss: 5.035383224487305\n",
      "Epoch 26/750, Training Loss: 5.082353115081787, Validation Loss: 4.698314666748047\n",
      "Epoch 27/750, Training Loss: 4.755245208740234, Validation Loss: 4.366392135620117\n",
      "Epoch 28/750, Training Loss: 4.434197425842285, Validation Loss: 4.041599273681641\n",
      "Epoch 29/750, Training Loss: 4.104709148406982, Validation Loss: 3.726057291030884\n",
      "Epoch 30/750, Training Loss: 3.806755781173706, Validation Loss: 3.422053575515747\n",
      "Epoch 31/750, Training Loss: 3.5064780712127686, Validation Loss: 3.1319642066955566\n",
      "Epoch 32/750, Training Loss: 3.2303225994110107, Validation Loss: 2.858241319656372\n",
      "Epoch 33/750, Training Loss: 2.970583915710449, Validation Loss: 2.6033167839050293\n",
      "Epoch 34/750, Training Loss: 2.7173244953155518, Validation Loss: 2.369554042816162\n",
      "Epoch 35/750, Training Loss: 2.4975714683532715, Validation Loss: 2.159071683883667\n",
      "Epoch 36/750, Training Loss: 2.2982637882232666, Validation Loss: 1.973649263381958\n",
      "Epoch 37/750, Training Loss: 2.1218204498291016, Validation Loss: 1.814612627029419\n",
      "Epoch 38/750, Training Loss: 1.9760167598724365, Validation Loss: 1.6826553344726562\n",
      "Epoch 39/750, Training Loss: 1.8560630083084106, Validation Loss: 1.5776807069778442\n",
      "Epoch 40/750, Training Loss: 1.7836557626724243, Validation Loss: 1.4987467527389526\n",
      "Epoch 41/750, Training Loss: 1.7103065252304077, Validation Loss: 1.4439176321029663\n",
      "Epoch 42/750, Training Loss: 1.6679681539535522, Validation Loss: 1.4103307723999023\n",
      "Epoch 43/750, Training Loss: 1.6557899713516235, Validation Loss: 1.394329309463501\n",
      "Epoch 44/750, Training Loss: 1.645930528640747, Validation Loss: 1.3916155099868774\n",
      "Epoch 45/750, Training Loss: 1.653738260269165, Validation Loss: 1.3975956439971924\n",
      "Epoch 46/750, Training Loss: 1.6710808277130127, Validation Loss: 1.407809853553772\n",
      "Epoch 47/750, Training Loss: 1.685707926750183, Validation Loss: 1.4183217287063599\n",
      "Epoch 48/750, Training Loss: 1.7042399644851685, Validation Loss: 1.425920844078064\n",
      "Epoch 49/750, Training Loss: 1.7183159589767456, Validation Loss: 1.4284383058547974\n",
      "Epoch 50/750, Training Loss: 1.7173492908477783, Validation Loss: 1.4248381853103638\n",
      "Epoch 51/750, Training Loss: 1.7240902185440063, Validation Loss: 1.4149428606033325\n",
      "Epoch 52/750, Training Loss: 1.723381757736206, Validation Loss: 1.399429202079773\n",
      "Epoch 53/750, Training Loss: 1.6883057355880737, Validation Loss: 1.3796143531799316\n",
      "Epoch 54/750, Training Loss: 1.6698012351989746, Validation Loss: 1.357054591178894\n",
      "Epoch 55/750, Training Loss: 1.6381752490997314, Validation Loss: 1.3334064483642578\n",
      "Epoch 56/750, Training Loss: 1.6225793361663818, Validation Loss: 1.3101328611373901\n",
      "Epoch 57/750, Training Loss: 1.5782383680343628, Validation Loss: 1.2885615825653076\n",
      "Epoch 58/750, Training Loss: 1.5538989305496216, Validation Loss: 1.2696369886398315\n",
      "Epoch 59/750, Training Loss: 1.5340912342071533, Validation Loss: 1.2539530992507935\n",
      "Epoch 60/750, Training Loss: 1.5108126401901245, Validation Loss: 1.2417529821395874\n",
      "Epoch 61/750, Training Loss: 1.4976427555084229, Validation Loss: 1.2329939603805542\n",
      "Epoch 62/750, Training Loss: 1.4798108339309692, Validation Loss: 1.2274088859558105\n",
      "Epoch 63/750, Training Loss: 1.46860933303833, Validation Loss: 1.2245336771011353\n",
      "Epoch 64/750, Training Loss: 1.4603257179260254, Validation Loss: 1.2238062620162964\n",
      "Epoch 65/750, Training Loss: 1.4498599767684937, Validation Loss: 1.2246109247207642\n",
      "Epoch 66/750, Training Loss: 1.4549604654312134, Validation Loss: 1.2263437509536743\n",
      "Epoch 67/750, Training Loss: 1.4481080770492554, Validation Loss: 1.228439450263977\n",
      "Epoch 68/750, Training Loss: 1.4468187093734741, Validation Loss: 1.2304203510284424\n",
      "Epoch 69/750, Training Loss: 1.4420673847198486, Validation Loss: 1.2318907976150513\n",
      "Epoch 70/750, Training Loss: 1.4463781118392944, Validation Loss: 1.2325975894927979\n",
      "Epoch 71/750, Training Loss: 1.4474973678588867, Validation Loss: 1.232338547706604\n",
      "Epoch 72/750, Training Loss: 1.4454137086868286, Validation Loss: 1.2309985160827637\n",
      "Epoch 73/750, Training Loss: 1.4474551677703857, Validation Loss: 1.2286019325256348\n",
      "Epoch 74/750, Training Loss: 1.4296170473098755, Validation Loss: 1.2251875400543213\n",
      "Epoch 75/750, Training Loss: 1.432450532913208, Validation Loss: 1.2208588123321533\n",
      "Epoch 76/750, Training Loss: 1.4219788312911987, Validation Loss: 1.2157864570617676\n",
      "Epoch 77/750, Training Loss: 1.4205706119537354, Validation Loss: 1.2101800441741943\n",
      "Epoch 78/750, Training Loss: 1.411594271659851, Validation Loss: 1.2042187452316284\n",
      "Epoch 79/750, Training Loss: 1.4071398973464966, Validation Loss: 1.1980960369110107\n",
      "Epoch 80/750, Training Loss: 1.4061942100524902, Validation Loss: 1.1919723749160767\n",
      "Epoch 81/750, Training Loss: 1.4065061807632446, Validation Loss: 1.1860123872756958\n",
      "Epoch 82/750, Training Loss: 1.4045426845550537, Validation Loss: 1.1803319454193115\n",
      "Epoch 83/750, Training Loss: 1.3938950300216675, Validation Loss: 1.175034761428833\n",
      "Epoch 84/750, Training Loss: 1.3819941282272339, Validation Loss: 1.1701605319976807\n",
      "Epoch 85/750, Training Loss: 1.382912278175354, Validation Loss: 1.165714979171753\n",
      "Epoch 86/750, Training Loss: 1.3794976472854614, Validation Loss: 1.161699652671814\n",
      "Epoch 87/750, Training Loss: 1.375674843788147, Validation Loss: 1.1580826044082642\n",
      "Epoch 88/750, Training Loss: 1.377040147781372, Validation Loss: 1.1548330783843994\n",
      "Epoch 89/750, Training Loss: 1.3691209554672241, Validation Loss: 1.1518927812576294\n",
      "Epoch 90/750, Training Loss: 1.368709683418274, Validation Loss: 1.1491999626159668\n",
      "Epoch 91/750, Training Loss: 1.373584508895874, Validation Loss: 1.1467058658599854\n",
      "Epoch 92/750, Training Loss: 1.3613327741622925, Validation Loss: 1.1443721055984497\n",
      "Epoch 93/750, Training Loss: 1.363126277923584, Validation Loss: 1.1421682834625244\n",
      "Epoch 94/750, Training Loss: 1.3575912714004517, Validation Loss: 1.140057921409607\n",
      "Epoch 95/750, Training Loss: 1.3505945205688477, Validation Loss: 1.1380211114883423\n",
      "Epoch 96/750, Training Loss: 1.3478007316589355, Validation Loss: 1.1360630989074707\n",
      "Epoch 97/750, Training Loss: 1.356945514678955, Validation Loss: 1.1341748237609863\n",
      "Epoch 98/750, Training Loss: 1.3445059061050415, Validation Loss: 1.1323587894439697\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m predictions \u001b[39m=\u001b[39m model(X_train_tensor)\n\u001b[1;32m      8\u001b[0m loss \u001b[39m=\u001b[39m criterion(predictions, y_train_tensor)\n\u001b[0;32m----> 9\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     10\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     12\u001b[0m \u001b[39m# Validate\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/distributed info/-CS-423-Project-2/.venv/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/distributed info/-CS-423-Project-2/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 750\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    predictions = model(X_train_tensor)\n",
    "    loss = criterion(predictions, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Validate\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_predictions = model(X_val_tensor)\n",
    "        val_loss = criterion(val_predictions, y_val_tensor)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n",
    "\n",
    "# 7. Evaluate\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_predictions = model(X_val_tensor)\n",
    "    val_predictions_clipped = torch.clamp(val_predictions, 0.5, 5.0)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val_tensor.cpu(), val_predictions_clipped.cpu()))\n",
    "    print(f\"Validation RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global average rating\n",
    "global_avg_rating = train['rating'].mean()\n",
    "\n",
    "# User-specific average rating\n",
    "user_avg_ratings = train.groupby('userId')['rating'].mean().to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test data to tensor\n",
    "X_test = test[['user', 'movie'] + mlb.classes_.tolist()]\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20168, 22])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_test_tensor)\n",
    "    # Clip the predictions between 0.5 and 5.0\n",
    "    test_predictions_clipped = torch.clamp(test_predictions, 0.5, 5.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tensor to dataframe and save to csv for submission\n",
    "submission_df = pd.DataFrame({'Id': test['Id'], 'rating': test_predictions_clipped.cpu().numpy()})\n",
    "submission_df.to_csv('submission_custom_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
