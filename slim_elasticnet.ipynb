{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, lil_matrix, save_npz, load_npz\n",
    "from joblib import Parallel, delayed\n",
    "import csv\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "train_ratings = pd.read_csv(f'{DATA_DIR}/train_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def create_user_item_matrix(df):\n",
    "    \"\"\" Create a user-item matrix for collaborative filtering \"\"\"\n",
    "    user_ids = df['userId'].unique()\n",
    "    movie_ids = df['movieId'].unique()\n",
    "    \n",
    "    user_id_to_idx = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "    movie_id_to_idx = {movie_id: idx for idx, movie_id in enumerate(movie_ids)}\n",
    "    \n",
    "    rows = df['userId'].map(user_id_to_idx)\n",
    "    cols = df['movieId'].map(movie_id_to_idx)\n",
    "    values = df['rating']\n",
    "    \n",
    "    return csr_matrix((values, (rows, cols)), shape=(len(user_ids), len(movie_ids))), user_id_to_idx, movie_id_to_idx\n",
    "\n",
    "# Create user-item matrices for train data\n",
    "train_matrix, train_user_id_to_idx, train_movie_id_to_idx = create_user_item_matrix(train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = train_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_rating = min(train_ratings['rating'])\n",
    "max_rating = max(train_ratings['rating'])\n",
    "global_mean = train_ratings['rating'].mean()\n",
    "min_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize train_matrix\n",
    "train_matrix = (train_matrix)/(max_rating - min_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66666667, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.88888889, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.66666667, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 3000), (3000, 6000), (6000, 8983)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create batches for elasticNet training\n",
    "batches = []\n",
    "i = 0\n",
    "increment = 3000\n",
    "while i < train_matrix.shape[1]:\n",
    "    batches.append((i, min(i+increment, train_matrix.shape[1])))\n",
    "    i += increment\n",
    "batches    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 96/3000 [00:20<02:30, 19.33it/s]"
     ]
    }
   ],
   "source": [
    "def train_slim_parallel(data, l1_reg=0.001, l2_reg=0.001, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Train SLIM model\n",
    "    :param data: User-rating matrix.\n",
    "    :param l1_reg: L1 regularization parameter.\n",
    "    :param l2_reg: L2 regularization parameter.\n",
    "    :param n_jobs: Number of parallel jobs.\n",
    "    :return: Weight matrix W\n",
    "    \"\"\"\n",
    "    n_items = data.shape[1]\n",
    "    sim_matrix = lil_matrix((n_items, n_items))\n",
    "\n",
    "    def train_item(item):\n",
    "        target = data[:, item].ravel()  \n",
    "\n",
    "        predictors = data.copy()\n",
    "        predictors[:, item] = 0 \n",
    "\n",
    "        model = ElasticNet(alpha=l1_reg + l2_reg, l1_ratio=l1_reg / (l1_reg + l2_reg), fit_intercept=False, positive=True)\n",
    "        model.fit(predictors, target)\n",
    "\n",
    "        return model.coef_\n",
    "\n",
    "    for batch in batches:\n",
    "        results = Parallel(n_jobs=n_jobs)(delayed(train_item)(item) for item in tqdm(range(batch[0], batch[1])))\n",
    "        for item, coef in enumerate(results):\n",
    "            index = batch[0] + item\n",
    "            sim_matrix[:, index] = coef\n",
    "        with open(f\"npz_result_{batch[1]}.npz\", 'wb') as f:\n",
    "            save_npz(f, csr_matrix(sim_matrix))\n",
    "\n",
    "    return csr_matrix(sim_matrix)\n",
    "\n",
    "\n",
    "w_matrix = train_slim_parallel(train_matrix,0.001,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8983x8983 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 245578 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_matrix = w_matrix.toarray()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
